{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb11ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935f7186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5f0d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marthinwurer/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import minerl\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utilities import flatten, unflatten, to_batch_shape, to_torch_channels\n",
    "\n",
    "import autoencoder\n",
    "from AdvancedAutoencoder import AdvancedAutoencoder\n",
    "from networks import WMAutoencoder, WM_VAE, VisionEncoder, VisionDecoder, VAELatent\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset_preprocessing import MineRlSequenceDataset\n",
    "import torch.distributions as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639a960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 512\n",
    "# BATCH_SIZE = 256\n",
    "# BATCH_SIZE = 128\n",
    "# BATCH_SIZE = 64\n",
    "# BATCH_SIZE = 32\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 30\n",
    "MOMENTUM = 0.9\n",
    "# IN_POWER = 8\n",
    "# IN_POWER = 6\n",
    "in_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108343c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd0e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(n=512):\n",
    "    y = np.linspace(-1, 1, n)\n",
    "    x = 7 * np.sin(5 * y) + 0.5 * y + 0.5 * np.random.randn(*y.shape)\n",
    "    return x[:,np.newaxis], y[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b34a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMDN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_gaussians):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.num_gaussians = num_gaussians\n",
    "        num_outs = output_size * num_gaussians\n",
    "        self.pi = nn.Sequential(nn.Linear(input_size, num_outs), nn.Softplus())\n",
    "        self.mu = nn.Linear(input_size, num_outs)\n",
    "        self.sigma = nn.Sequential(nn.Linear(input_size, num_outs), nn.Softplus())\n",
    "        \n",
    "    def forward(self, input):\n",
    "        pi = self.pi(input).view(input.shape[0], self.output_size, self.num_gaussians)\n",
    "        mu = self.mu(input).view(input.shape[0], self.output_size, self.num_gaussians)\n",
    "        sigma = self.sigma(input).view(input.shape[0], self.output_size, self.num_gaussians)\n",
    "        return pi, sigma, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd940cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_distribution(pi, sigma, mu):\n",
    "    mix = D.Categorical(pi)\n",
    "    comp = D.Normal(mu, sigma)\n",
    "\n",
    "    gm = D.MixtureSameFamily(mix, comp)\n",
    "    return gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c182be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_gnll_loss(pi, sigma, mu, target):\n",
    "    \n",
    "    gm = mdn_distribution(pi, sigma, mu)\n",
    "    log_likelihood = gm.log_prob(target)\n",
    "    return -torch.mean(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5815d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_data()\n",
    "x = torch.Tensor(x)\n",
    "y = torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac21950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(1, 10), nn.ELU(), MyMDN(10, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf55454",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5901f6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\tLoss: 1.62\n",
      "Iter: 100\tLoss: -0.01\n",
      "Iter: 200\tLoss: -0.11\n",
      "Iter: 300\tLoss: -0.14\n",
      "Iter: 400\tLoss: -0.19\n",
      "Iter: 500\tLoss: -0.32\n",
      "Iter: 600\tLoss: -0.38\n",
      "Iter: 700\tLoss: -0.52\n",
      "Iter: 800\tLoss: -0.59\n",
      "Iter: 900\tLoss: -0.60\n",
      "Iter: 1000\tLoss: -0.62\n",
      "Iter: 1100\tLoss: -0.65\n",
      "Iter: 1200\tLoss: -0.66\n",
      "Iter: 1300\tLoss: -0.65\n",
      "Iter: 1400\tLoss: -0.66\n",
      "Iter: 1500\tLoss: -0.66\n",
      "Iter: 1600\tLoss: -0.66\n",
      "Iter: 1700\tLoss: -0.67\n",
      "Iter: 1800\tLoss: -0.66\n",
      "Iter: 1900\tLoss: -0.67\n",
      "Iter: 2000\tLoss: -0.68\n",
      "Iter: 2100\tLoss: -0.68\n",
      "Iter: 2200\tLoss: -0.68\n",
      "Iter: 2300\tLoss: -0.69\n",
      "Iter: 2400\tLoss: -0.69\n",
      "Iter: 2500\tLoss: -0.69\n",
      "Iter: 2600\tLoss: -0.69\n",
      "Iter: 2700\tLoss: -0.70\n",
      "Iter: 2800\tLoss: -0.70\n",
      "Iter: 2900\tLoss: -0.70\n",
      "Iter: 3000\tLoss: -0.71\n",
      "Iter: 3100\tLoss: -0.70\n",
      "Iter: 3200\tLoss: -0.71\n",
      "Iter: 3300\tLoss: -0.71\n",
      "Iter: 3400\tLoss: -0.71\n",
      "Iter: 3500\tLoss: -0.72\n",
      "Iter: 3600\tLoss: -0.72\n",
      "Iter: 3700\tLoss: -0.70\n",
      "Iter: 3800\tLoss: -0.72\n",
      "Iter: 3900\tLoss: -0.73\n",
      "Iter: 4000\tLoss: -0.73\n",
      "Iter: 4100\tLoss: -0.72\n",
      "Iter: 4200\tLoss: -0.73\n",
      "Iter: 4300\tLoss: -0.72\n",
      "Iter: 4400\tLoss: -0.73\n",
      "Iter: 4500\tLoss: -0.73\n",
      "Iter: 4600\tLoss: -0.73\n",
      "Iter: 4700\tLoss: -0.73\n",
      "Iter: 4800\tLoss: -0.72\n",
      "Iter: 4900\tLoss: -0.44\n",
      "Iter: 5000\tLoss: -0.76\n",
      "Iter: 5100\tLoss: -0.81\n",
      "Iter: 5200\tLoss: -0.90\n",
      "Iter: 5300\tLoss: -0.93\n",
      "Iter: 5400\tLoss: -1.00\n",
      "Iter: 5500\tLoss: -0.76\n",
      "Iter: 5600\tLoss: -1.12\n",
      "Iter: 5700\tLoss: -1.13\n",
      "Iter: 5800\tLoss: -1.13\n",
      "Iter: 5900\tLoss: -1.14\n",
      "Iter: 6000\tLoss: -1.14\n",
      "Iter: 6100\tLoss: -1.14\n",
      "Iter: 6200\tLoss: -1.15\n",
      "Iter: 6300\tLoss: -1.15\n",
      "Iter: 6400\tLoss: -1.12\n",
      "Iter: 6500\tLoss: -1.17\n",
      "Iter: 6600\tLoss: -1.17\n",
      "Iter: 6700\tLoss: -1.17\n",
      "Iter: 6800\tLoss: -1.16\n",
      "Iter: 6900\tLoss: -1.18\n",
      "Iter: 7000\tLoss: -1.18\n",
      "Iter: 7100\tLoss: -1.13\n",
      "Iter: 7200\tLoss: -1.18\n",
      "Iter: 7300\tLoss: -1.19\n",
      "Iter: 7400\tLoss: -1.19\n",
      "Iter: 7500\tLoss: -1.18\n",
      "Iter: 7600\tLoss: -1.18\n",
      "Iter: 7700\tLoss: -1.19\n",
      "Iter: 7800\tLoss: -1.19\n",
      "Iter: 7900\tLoss: -1.19\n",
      "Iter: 8000\tLoss: -1.18\n",
      "Iter: 8100\tLoss: -1.20\n",
      "Iter: 8200\tLoss: -1.16\n",
      "Iter: 8300\tLoss: -1.20\n",
      "Iter: 8400\tLoss: -1.20\n",
      "Iter: 8500\tLoss: -1.18\n",
      "Iter: 8600\tLoss: -1.20\n",
      "Iter: 8700\tLoss: -1.20\n",
      "Iter: 8800\tLoss: -1.20\n",
      "Iter: 8900\tLoss: -1.20\n",
      "Iter: 9000\tLoss: -1.19\n",
      "Iter: 9100\tLoss: -1.20\n",
      "Iter: 9200\tLoss: -1.19\n",
      "Iter: 9300\tLoss: -1.18\n",
      "Iter: 9400\tLoss: -1.21\n",
      "Iter: 9500\tLoss: -1.21\n",
      "Iter: 9600\tLoss: -1.20\n",
      "Iter: 9700\tLoss: -1.21\n",
      "Iter: 9800\tLoss: -1.21\n",
      "Iter: 9900\tLoss: -1.21\n",
      "Iter: 10000\tLoss: -1.20\n",
      "Iter: 10100\tLoss: -1.21\n",
      "Iter: 10200\tLoss: -1.21\n",
      "Iter: 10300\tLoss: -1.21\n",
      "Iter: 10400\tLoss: -1.21\n",
      "Iter: 10500\tLoss: -1.21\n",
      "Iter: 10600\tLoss: -1.21\n",
      "Iter: 10700\tLoss: -1.21\n",
      "Iter: 10800\tLoss: -1.22\n",
      "Iter: 10900\tLoss: -1.21\n",
      "Iter: 11000\tLoss: -1.17\n",
      "Iter: 11100\tLoss: -1.22\n",
      "Iter: 11200\tLoss: -1.21\n",
      "Iter: 11300\tLoss: -1.21\n",
      "Iter: 11400\tLoss: -1.22\n",
      "Iter: 11500\tLoss: -1.22\n",
      "Iter: 11600\tLoss: -1.21\n",
      "Iter: 11700\tLoss: -1.22\n",
      "Iter: 11800\tLoss: -1.19\n",
      "Iter: 11900\tLoss: -1.22\n",
      "Iter: 12000\tLoss: -1.22\n",
      "Iter: 12100\tLoss: -1.22\n",
      "Iter: 12200\tLoss: -1.20\n",
      "Iter: 12300\tLoss: -1.21\n",
      "Iter: 12400\tLoss: -1.22\n",
      "Iter: 12500\tLoss: -1.22\n",
      "Iter: 12600\tLoss: -1.22\n",
      "Iter: 12700\tLoss: -1.20\n",
      "Iter: 12800\tLoss: -1.22\n",
      "Iter: 12900\tLoss: -1.21\n",
      "Iter: 13000\tLoss: -1.22\n",
      "Iter: 13100\tLoss: -1.22\n",
      "Iter: 13200\tLoss: -1.22\n",
      "Iter: 13300\tLoss: -1.21\n",
      "Iter: 13400\tLoss: -1.23\n",
      "Iter: 13500\tLoss: -1.21\n",
      "Iter: 13600\tLoss: -1.22\n",
      "Iter: 13700\tLoss: -1.23\n",
      "Iter: 13800\tLoss: -1.23\n",
      "Iter: 13900\tLoss: -1.22\n",
      "Iter: 14000\tLoss: -1.23\n",
      "Iter: 14100\tLoss: -1.22\n",
      "Iter: 14200\tLoss: -1.23\n",
      "Iter: 14300\tLoss: -1.23\n",
      "Iter: 14400\tLoss: -1.19\n",
      "Iter: 14500\tLoss: -1.23\n",
      "Iter: 14600\tLoss: -1.23\n",
      "Iter: 14700\tLoss: -1.23\n",
      "Iter: 14800\tLoss: -1.06\n",
      "Iter: 14900\tLoss: -1.23\n",
      "Iter: 15000\tLoss: -1.23\n",
      "Iter: 15100\tLoss: -1.23\n",
      "Iter: 15200\tLoss: -1.22\n",
      "Iter: 15300\tLoss: -1.23\n",
      "Iter: 15400\tLoss: -1.18\n",
      "Iter: 15500\tLoss: -1.23\n",
      "Iter: 15600\tLoss: -1.22\n",
      "Iter: 15700\tLoss: -1.22\n",
      "Iter: 15800\tLoss: -1.23\n",
      "Iter: 15900\tLoss: -1.22\n",
      "Iter: 16000\tLoss: -1.21\n",
      "Iter: 16100\tLoss: -1.23\n",
      "Iter: 16200\tLoss: -1.23\n",
      "Iter: 16300\tLoss: -1.23\n",
      "Iter: 16400\tLoss: -1.22\n",
      "Iter: 16500\tLoss: -1.23\n",
      "Iter: 16600\tLoss: -1.21\n",
      "Iter: 16700\tLoss: -1.10\n",
      "Iter: 16800\tLoss: -1.23\n",
      "Iter: 16900\tLoss: -1.23\n",
      "Iter: 17000\tLoss: -1.23\n",
      "Iter: 17100\tLoss: -1.23\n",
      "Iter: 17200\tLoss: -1.19\n",
      "Iter: 17300\tLoss: -1.23\n",
      "Iter: 17400\tLoss: -1.23\n",
      "Iter: 17500\tLoss: -1.23\n",
      "Iter: 17600\tLoss: -1.21\n",
      "Iter: 17700\tLoss: -1.23\n",
      "Iter: 17800\tLoss: -1.21\n",
      "Iter: 17900\tLoss: -1.22\n",
      "Iter: 18000\tLoss: -1.23\n",
      "Iter: 18100\tLoss: -1.23\n",
      "Iter: 18200\tLoss: -1.22\n",
      "Iter: 18300\tLoss: -1.23\n",
      "Iter: 18400\tLoss: -1.23\n",
      "Iter: 18500\tLoss: -1.22\n",
      "Iter: 18600\tLoss: -1.23\n",
      "Iter: 18700\tLoss: -1.23\n",
      "Iter: 18800\tLoss: -1.23\n",
      "Iter: 18900\tLoss: -1.23\n",
      "Iter: 19000\tLoss: -1.23\n",
      "Iter: 19100\tLoss: -1.23\n",
      "Iter: 19200\tLoss: -0.72\n",
      "Iter: 19300\tLoss: -1.23\n",
      "Iter: 19400\tLoss: -1.23\n",
      "Iter: 19500\tLoss: -1.23\n",
      "Iter: 19600\tLoss: -1.23\n",
      "Iter: 19700\tLoss: -1.23\n",
      "Iter: 19800\tLoss: -1.23\n",
      "Iter: 19900\tLoss: -1.24\n"
     ]
    }
   ],
   "source": [
    "for i in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    pi, sigma, mu = model(x)\n",
    "    loss = mdn_gnll_loss(pi, sigma, mu, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iter: {i}\\t\" + f\"Loss: {loss.data:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea51fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x, y):\n",
    "    plt.hist2d(x, y, bins=35)\n",
    "    plt.xlim(-8, 8)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40b4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi, sigma, mu = model(x)\n",
    "samples = mdn_distribution(pi, sigma, mu).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbcac535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_data(x[:,0].numpy(), y[:,0].numpy())\n",
    "plt.title(\"Observed data\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_data(x[:,0].numpy(), samples[:,0].numpy())\n",
    "plt.title(\"Sampled data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616dce66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59de91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
