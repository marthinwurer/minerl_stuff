{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132a30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "action_to_vector = {\n",
    "    0: np.array([0, -1]),  # Up\n",
    "    1: np.array([1, 0]),   # Right\n",
    "    2: np.array([0, 1]),   # Down\n",
    "    3: np.array([-1, 0])   # Left\n",
    "}\n",
    "\n",
    "class DotEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.width = 64\n",
    "        self.height = 64\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(self.height, self.width, 3), dtype=np.uint8)\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.dot_position = np.array([0, 0], dtype='int32')\n",
    "        self.dot_color = np.array([255, 255, 255])\n",
    "        self.goal_position = np.array([self.width/2, self.height/2], dtype='int32')\n",
    "        self.viewer = None\n",
    "        self.reward_range = (-float('inf'), float('inf'))\n",
    "        self.max_episode_steps = 200\n",
    "        self.current_step = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        # Move the dot according to the action\n",
    "        if action == 0:  # Up\n",
    "            self.dot_position[1] = max(self.dot_position[1] - 1, 0)\n",
    "        elif action == 1:  # Right\n",
    "            self.dot_position[0] = min(self.dot_position[0] + 1, self.width - 2)\n",
    "        elif action == 2:  # Down\n",
    "            self.dot_position[1] = min(self.dot_position[1] + 1, self.height - 2)\n",
    "        elif action == 3:  # Left\n",
    "            self.dot_position[0] = max(self.dot_position[0] - 1, 0)\n",
    "\n",
    "        # Compute the reward based on the new position of the dot\n",
    "        distance = np.linalg.norm(self.dot_position - self.goal_position)\n",
    "        reward = 1 if distance < np.linalg.norm(self.dot_position - action_to_vector[action] - self.goal_position) else -1\n",
    "\n",
    "        # Update the observation\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.max_episode_steps or all(self.dot_position == self.goal_position)\n",
    "        info = {}\n",
    "\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def get_obs(self):\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "        return observation\n",
    "\n",
    "    def reset(self):\n",
    "        self.dot_position = np.array([np.random.randint(0, self.width - 2), np.random.randint(0, self.height - 2)])\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "        self.current_step = 0\n",
    "        return observation\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.SimpleImageViewer()\n",
    "        self.viewer.imshow(self.reset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22505202",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | -4.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 8074     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 19786    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 200      |\n",
      "|    ep_rew_mean      | -1.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 8133     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 39786    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_934096/1556547452.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    263\u001b[0m     ) -> SelfDQN:\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             rollout = self.collect_rollouts(\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mtrain_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;31m# Select action randomly or according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;31m# Rescale and perform action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36m_sample_action\u001b[0;34m(self, learning_starts, action_noise, n_envs)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# we assume that the policy uses tanh to scale the action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# We use non-deterministic action in the case of SAC, for TD3, it does not matter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0munscaled_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Rescale the action from [low, high] to [-1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;31m# Convert to numpy, and reshape to the original action shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/dqn/policies.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_constructor_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/dqn/policies.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Greedy action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/dqn/policies.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mestimated\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mValue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "env = DotEnv()\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1, gamma=0.0)\n",
    "model.learn(total_timesteps=100000, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d89b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "class ContinuousDotEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.width = 64\n",
    "        self.height = 64\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(self.height, self.width, 3), dtype=np.uint8)\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(2,), dtype=np.float32)\n",
    "        self.dot_position = np.array([0, 0], dtype='int32')\n",
    "        self.dot_color = np.array([255, 255, 255])\n",
    "        self.goal_position = np.array([self.width/2, self.height/2], dtype='int32')\n",
    "        self.viewer = None\n",
    "        self.reward_range = (-float('inf'), float('inf'))\n",
    "        self.max_episode_steps = 200\n",
    "        self.current_step = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        # Move the dot according to the action\n",
    "        action = np.clip(action, self.action_space.low, self.action_space.high)\n",
    "        self.dot_position[0] = np.clip(self.dot_position[0] + action[0], 0, self.width - 2)\n",
    "        self.dot_position[1] = np.clip(self.dot_position[1] + action[1], 0, self.height - 2)\n",
    "\n",
    "        # Compute the reward based on the new position of the dot\n",
    "        distance = np.linalg.norm(self.dot_position - self.goal_position)\n",
    "        reward = 1 if distance < np.linalg.norm(self.dot_position - action - self.goal_position) else -1\n",
    "\n",
    "        # Update the observation\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.max_episode_steps or all(self.dot_position == self.goal_position)\n",
    "        info = {}\n",
    "\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def get_obs(self):\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "        return observation\n",
    "\n",
    "    def reset(self):\n",
    "        self.dot_position = np.array([np.random.randint(0, self.width - 2), np.random.randint(0, self.height - 2)])\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "        self.current_step = 0\n",
    "        return observation\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.SimpleImageViewer()\n",
    "        self.viewer.imshow(self.reset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbbde3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_934096/3881304395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    123\u001b[0m     ) -> SelfDDPG:\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    212\u001b[0m     ) -> SelfTD3:\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# Compute actor loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq1_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mactor_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;31m# Optimize the actor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "env = ContinuousDotEnv()\n",
    "\n",
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=100000, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f95435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBDotEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    An environment with sparse rewards. \n",
    "    Three dots are scattered randomly around the screen,\n",
    "    and the agent gets +1 reward for each one they touch in order.\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    colors = [\n",
    "        np.array([255, 0, 0]),\n",
    "        np.array([0, 255, 0]),\n",
    "        np.array([0, 0, 255]),\n",
    "    ]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(64, 64, 3), dtype=np.uint8)\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.dot_position = np.array([0, 0], dtype='int32')\n",
    "        self.dot_color = np.array([255, 255, 255])\n",
    "        self.viewer = None\n",
    "        self.reward_range = (-float('inf'), float('inf'))\n",
    "        self.current_step = 0\n",
    "        self.colored_dots = []\n",
    "\n",
    "    def step(self, action):\n",
    "        # Move the dot according to the action\n",
    "        if action == 0:  # Up\n",
    "            self.dot_position[1] = max(self.dot_position[1] - 1, 0)\n",
    "        elif action == 1:  # Right\n",
    "            self.dot_position[0] = min(self.dot_position[0] + 1, 64 - 2)\n",
    "        elif action == 2:  # Down\n",
    "            self.dot_position[1] = min(self.dot_position[1] + 1, 64 - 2)\n",
    "        elif action == 3:  # Left\n",
    "            self.dot_position[0] = max(self.dot_position[0] - 1, 0)\n",
    "\n",
    "        # Compute the reward based on the new position of the dot\n",
    "        reward = 0\n",
    "        if all(self.dot_position == self.colored_dots[0][0]):\n",
    "            reward = 1\n",
    "            self.colored_dots.pop(0)\n",
    "            \n",
    "        self.current_step += 1\n",
    "        done = len(self.colored_dots) == 0 or self.current_step >= 1000\n",
    "        info = {}\n",
    "\n",
    "        # Update the observation\n",
    "        observation = self.get_obs()\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def render_dot(self, obs, position, color):\n",
    "        obs[position[1]:position[1]+2, position[0]:position[0]+2] = color\n",
    "    \n",
    "    def get_obs(self):\n",
    "        observation = np.zeros((64, 64, 3), dtype=np.uint8)\n",
    "\n",
    "        # render the dots in reverse order to ensure that the target is always visible\n",
    "        for p, c in reversed(self.colored_dots):\n",
    "            self.render_dot(observation, p, c)\n",
    "\n",
    "        self.render_dot(observation, self.dot_position, np.array([255, 255, 255]))\n",
    "        return observation\n",
    "    \n",
    "    def rand_point(self):\n",
    "        return np.array([np.random.randint(0, 64 - 2), np.random.randint(0, 64 - 2)])\n",
    "        \n",
    "    def reset(self):\n",
    "        self.dot_position = self.rand_point()\n",
    "        self.current_step = 0\n",
    "        self.colored_dots = []\n",
    "        for c in self.colors:\n",
    "            self.colored_dots.append((self.rand_point(), c))\n",
    "        observation = self.get_obs()\n",
    "        return observation\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.SimpleImageViewer()\n",
    "        self.viewer.imshow(self.get_obs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04779ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RGBDotEnv()\n",
    "observation = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    action = env.action_space.sample()  # Replace with your policy\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "#     env.render()\n",
    "print(f'Total reward: {total_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 8]\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3139598",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1ab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marthinwurer/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 24.59GB > 18.72GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.3      |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 10       |\n",
      "|    fps              | 8451     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 10000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 8706     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 20000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.133    |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 30       |\n",
      "|    fps              | 8770     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 30000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.1      |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 8708     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 40000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 50       |\n",
      "|    fps              | 8760     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 50000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.0667   |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 4099     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.41e-06 |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.0714   |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 70       |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04e-05 |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.0875   |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 2463     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.79e-07 |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.0778   |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 90       |\n",
      "|    fps              | 2159     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.94e-06 |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1965     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39e-07 |\n",
      "|    n_updates        | 12499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 110      |\n",
      "|    fps              | 1830     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 110000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.35e-07 |\n",
      "|    n_updates        | 14999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 1731     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.95e-08 |\n",
      "|    n_updates        | 17499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 130      |\n",
      "|    fps              | 1654     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 130000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.48e-07 |\n",
      "|    n_updates        | 19999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 1594     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 140000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.66e-08 |\n",
      "|    n_updates        | 22499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 150      |\n",
      "|    fps              | 1543     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.41e-07 |\n",
      "|    n_updates        | 24999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 1505     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.62e-07 |\n",
      "|    n_updates        | 27499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 170      |\n",
      "|    fps              | 1469     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 170000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.9e-07  |\n",
      "|    n_updates        | 29999    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 1440     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 180000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.02e-07 |\n",
      "|    n_updates        | 32499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 190      |\n",
      "|    fps              | 1412     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 190000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.65e-08 |\n",
      "|    n_updates        | 34999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 1387     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.44e-08 |\n",
      "|    n_updates        | 37499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 210      |\n",
      "|    fps              | 1365     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 210000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.21e-08 |\n",
      "|    n_updates        | 39999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 1347     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 220000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28e-07 |\n",
      "|    n_updates        | 42499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    episodes         | 230      |\n",
      "|    fps              | 1328     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 230000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.3e-08  |\n",
      "|    n_updates        | 44999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.1      |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 1317     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 240000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.58e-08 |\n",
      "|    n_updates        | 47499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 250      |\n",
      "|    fps              | 1304     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.75e-07 |\n",
      "|    n_updates        | 49999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.753    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 1290     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 260000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.79e-07 |\n",
      "|    n_updates        | 52499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    episodes         | 270      |\n",
      "|    fps              | 1277     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 270000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.12e-08 |\n",
      "|    n_updates        | 54999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 1265     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 280000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.82e-08 |\n",
      "|    n_updates        | 57499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 290      |\n",
      "|    fps              | 1254     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 290000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32e-07 |\n",
      "|    n_updates        | 59999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 1243     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02e-07 |\n",
      "|    n_updates        | 62499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    episodes         | 310      |\n",
      "|    fps              | 1234     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 310000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.98e-08 |\n",
      "|    n_updates        | 64999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 1225     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 320000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.97e-08 |\n",
      "|    n_updates        | 67499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 330      |\n",
      "|    fps              | 1216     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 330000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.62e-07 |\n",
      "|    n_updates        | 69999    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.677    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 1207     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 340000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.94e-07 |\n",
      "|    n_updates        | 72499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    episodes         | 350      |\n",
      "|    fps              | 1199     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 350000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39e-07 |\n",
      "|    n_updates        | 74999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 1194     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 360000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.53e-08 |\n",
      "|    n_updates        | 77499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.648    |\n",
      "| time/               |          |\n",
      "|    episodes         | 370      |\n",
      "|    fps              | 1187     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 370000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.6e-08  |\n",
      "|    n_updates        | 79999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 1180     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 380000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.77e-08 |\n",
      "|    n_updates        | 82499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.629    |\n",
      "| time/               |          |\n",
      "|    episodes         | 390      |\n",
      "|    fps              | 1173     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 390000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.77e-08 |\n",
      "|    n_updates        | 84999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 1167     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17e-07 |\n",
      "|    n_updates        | 87499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.61     |\n",
      "| time/               |          |\n",
      "|    episodes         | 410      |\n",
      "|    fps              | 1160     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 410000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.83e-07 |\n",
      "|    n_updates        | 89999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 1155     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 420000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.81e-08 |\n",
      "|    n_updates        | 92499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.591    |\n",
      "| time/               |          |\n",
      "|    episodes         | 430      |\n",
      "|    fps              | 1150     |\n",
      "|    time_elapsed     | 373      |\n",
      "|    total_timesteps  | 430000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64e-07 |\n",
      "|    n_updates        | 94999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 1144     |\n",
      "|    time_elapsed     | 384      |\n",
      "|    total_timesteps  | 440000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.38e-09 |\n",
      "|    n_updates        | 97499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.572    |\n",
      "| time/               |          |\n",
      "|    episodes         | 450      |\n",
      "|    fps              | 1139     |\n",
      "|    time_elapsed     | 394      |\n",
      "|    total_timesteps  | 450000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.01e-08 |\n",
      "|    n_updates        | 99999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 1134     |\n",
      "|    time_elapsed     | 405      |\n",
      "|    total_timesteps  | 460000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.73e-08 |\n",
      "|    n_updates        | 102499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    episodes         | 470      |\n",
      "|    fps              | 1129     |\n",
      "|    time_elapsed     | 415      |\n",
      "|    total_timesteps  | 470000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.42e-08 |\n",
      "|    n_updates        | 104999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 1125     |\n",
      "|    time_elapsed     | 426      |\n",
      "|    total_timesteps  | 480000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7e-08  |\n",
      "|    n_updates        | 107499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.534    |\n",
      "| time/               |          |\n",
      "|    episodes         | 490      |\n",
      "|    fps              | 1120     |\n",
      "|    time_elapsed     | 437      |\n",
      "|    total_timesteps  | 490000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.52e-08 |\n",
      "|    n_updates        | 109999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 1116     |\n",
      "|    time_elapsed     | 447      |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.06e-08 |\n",
      "|    n_updates        | 112499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    episodes         | 510      |\n",
      "|    fps              | 1112     |\n",
      "|    time_elapsed     | 458      |\n",
      "|    total_timesteps  | 510000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.64e-08 |\n",
      "|    n_updates        | 114999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 1107     |\n",
      "|    time_elapsed     | 469      |\n",
      "|    total_timesteps  | 520000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49e-07 |\n",
      "|    n_updates        | 117499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 530      |\n",
      "|    fps              | 1104     |\n",
      "|    time_elapsed     | 480      |\n",
      "|    total_timesteps  | 530000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.87e-08 |\n",
      "|    n_updates        | 119999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 1101     |\n",
      "|    time_elapsed     | 490      |\n",
      "|    total_timesteps  | 540000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.71e-08 |\n",
      "|    n_updates        | 122499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.477    |\n",
      "| time/               |          |\n",
      "|    episodes         | 550      |\n",
      "|    fps              | 1097     |\n",
      "|    time_elapsed     | 501      |\n",
      "|    total_timesteps  | 550000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.61e-08 |\n",
      "|    n_updates        | 124999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 1094     |\n",
      "|    time_elapsed     | 511      |\n",
      "|    total_timesteps  | 560000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37e-07 |\n",
      "|    n_updates        | 127499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.458    |\n",
      "| time/               |          |\n",
      "|    episodes         | 570      |\n",
      "|    fps              | 1090     |\n",
      "|    time_elapsed     | 522      |\n",
      "|    total_timesteps  | 570000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.72e-08 |\n",
      "|    n_updates        | 129999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 1086     |\n",
      "|    time_elapsed     | 533      |\n",
      "|    total_timesteps  | 580000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.83e-07 |\n",
      "|    n_updates        | 132499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 590      |\n",
      "|    fps              | 1083     |\n",
      "|    time_elapsed     | 544      |\n",
      "|    total_timesteps  | 590000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.41e-08 |\n",
      "|    n_updates        | 134999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 1080     |\n",
      "|    time_elapsed     | 555      |\n",
      "|    total_timesteps  | 600000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.23e-07 |\n",
      "|    n_updates        | 137499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.421    |\n",
      "| time/               |          |\n",
      "|    episodes         | 610      |\n",
      "|    fps              | 1077     |\n",
      "|    time_elapsed     | 566      |\n",
      "|    total_timesteps  | 610000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.07e-07 |\n",
      "|    n_updates        | 139999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 1074     |\n",
      "|    time_elapsed     | 576      |\n",
      "|    total_timesteps  | 620000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6e-07  |\n",
      "|    n_updates        | 142499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    episodes         | 630      |\n",
      "|    fps              | 1071     |\n",
      "|    time_elapsed     | 587      |\n",
      "|    total_timesteps  | 630000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.89e-08 |\n",
      "|    n_updates        | 144999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 1068     |\n",
      "|    time_elapsed     | 598      |\n",
      "|    total_timesteps  | 640000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.93e-08 |\n",
      "|    n_updates        | 147499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    episodes         | 650      |\n",
      "|    fps              | 1065     |\n",
      "|    time_elapsed     | 609      |\n",
      "|    total_timesteps  | 650000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.84e-08 |\n",
      "|    n_updates        | 149999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 1062     |\n",
      "|    time_elapsed     | 620      |\n",
      "|    total_timesteps  | 660000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.01e-07 |\n",
      "|    n_updates        | 152499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    episodes         | 670      |\n",
      "|    fps              | 1060     |\n",
      "|    time_elapsed     | 631      |\n",
      "|    total_timesteps  | 670000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.51e-08 |\n",
      "|    n_updates        | 154999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 1058     |\n",
      "|    time_elapsed     | 642      |\n",
      "|    total_timesteps  | 680000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57e-08 |\n",
      "|    n_updates        | 157499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 690      |\n",
      "|    fps              | 1055     |\n",
      "|    time_elapsed     | 653      |\n",
      "|    total_timesteps  | 690000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.87e-09 |\n",
      "|    n_updates        | 159999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 1052     |\n",
      "|    time_elapsed     | 664      |\n",
      "|    total_timesteps  | 700000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.12e-07 |\n",
      "|    n_updates        | 162499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.326    |\n",
      "| time/               |          |\n",
      "|    episodes         | 710      |\n",
      "|    fps              | 1050     |\n",
      "|    time_elapsed     | 676      |\n",
      "|    total_timesteps  | 710000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.72e-08 |\n",
      "|    n_updates        | 164999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 1047     |\n",
      "|    time_elapsed     | 687      |\n",
      "|    total_timesteps  | 720000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.85e-08 |\n",
      "|    n_updates        | 167499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.1      |\n",
      "|    exploration_rate | 0.307    |\n",
      "| time/               |          |\n",
      "|    episodes         | 730      |\n",
      "|    fps              | 1045     |\n",
      "|    time_elapsed     | 698      |\n",
      "|    total_timesteps  | 730000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.73e-08 |\n",
      "|    n_updates        | 169999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 1043     |\n",
      "|    time_elapsed     | 709      |\n",
      "|    total_timesteps  | 740000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.14e-08 |\n",
      "|    n_updates        | 172499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    episodes         | 750      |\n",
      "|    fps              | 1040     |\n",
      "|    time_elapsed     | 720      |\n",
      "|    total_timesteps  | 750000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.57e-08 |\n",
      "|    n_updates        | 174999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 1038     |\n",
      "|    time_elapsed     | 731      |\n",
      "|    total_timesteps  | 760000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.94e-06 |\n",
      "|    n_updates        | 177499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.269    |\n",
      "| time/               |          |\n",
      "|    episodes         | 770      |\n",
      "|    fps              | 1036     |\n",
      "|    time_elapsed     | 743      |\n",
      "|    total_timesteps  | 770000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.4e-08  |\n",
      "|    n_updates        | 179999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 1033     |\n",
      "|    time_elapsed     | 754      |\n",
      "|    total_timesteps  | 780000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.38e-08 |\n",
      "|    n_updates        | 182499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.25     |\n",
      "| time/               |          |\n",
      "|    episodes         | 790      |\n",
      "|    fps              | 1031     |\n",
      "|    time_elapsed     | 765      |\n",
      "|    total_timesteps  | 790000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.37e-08 |\n",
      "|    n_updates        | 184999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 1029     |\n",
      "|    time_elapsed     | 776      |\n",
      "|    total_timesteps  | 800000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.82e-09 |\n",
      "|    n_updates        | 187499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    episodes         | 810      |\n",
      "|    fps              | 1028     |\n",
      "|    time_elapsed     | 787      |\n",
      "|    total_timesteps  | 810000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.15e-08 |\n",
      "|    n_updates        | 189999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 1026     |\n",
      "|    time_elapsed     | 799      |\n",
      "|    total_timesteps  | 820000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.24e-09 |\n",
      "|    n_updates        | 192499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.212    |\n",
      "| time/               |          |\n",
      "|    episodes         | 830      |\n",
      "|    fps              | 1024     |\n",
      "|    time_elapsed     | 810      |\n",
      "|    total_timesteps  | 830000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.8e-08  |\n",
      "|    n_updates        | 194999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 1022     |\n",
      "|    time_elapsed     | 821      |\n",
      "|    total_timesteps  | 840000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.31e-08 |\n",
      "|    n_updates        | 197499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    episodes         | 850      |\n",
      "|    fps              | 1019     |\n",
      "|    time_elapsed     | 833      |\n",
      "|    total_timesteps  | 850000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.44e-08 |\n",
      "|    n_updates        | 199999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 1017     |\n",
      "|    time_elapsed     | 844      |\n",
      "|    total_timesteps  | 860000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.53e-09 |\n",
      "|    n_updates        | 202499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.174    |\n",
      "| time/               |          |\n",
      "|    episodes         | 870      |\n",
      "|    fps              | 1015     |\n",
      "|    time_elapsed     | 856      |\n",
      "|    total_timesteps  | 870000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e-07 |\n",
      "|    n_updates        | 204999   |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = RGBDotEnv()\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1, gamma=0.0)\n",
    "model.learn(total_timesteps=10000000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5f0821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectDotsEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    An environment with sparse rewards. \n",
    "    Sixteen green dots are scattered randomly around the screen,\n",
    "    and the agent gets +1 reward for each one they touch.\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    colors = [\n",
    "        np.array([255, 0, 0]),\n",
    "        np.array([0, 255, 0]),\n",
    "        np.array([0, 0, 255]),\n",
    "    ]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(64, 64, 3), dtype=np.uint8)\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.dot_position = np.array([0, 0], dtype='int32')\n",
    "        self.dot_color = np.array([255, 255, 255])\n",
    "        self.viewer = None\n",
    "        self.reward_range = (-float('inf'), float('inf'))\n",
    "        self.current_step = 0\n",
    "        self.colored_dots = []\n",
    "\n",
    "    def step(self, action):\n",
    "        # Move the dot according to the action\n",
    "        if action == 0:  # Up\n",
    "            self.dot_position[1] = max(self.dot_position[1] - 1, 0)\n",
    "        elif action == 1:  # Right\n",
    "            self.dot_position[0] = min(self.dot_position[0] + 1, 64 - 2)\n",
    "        elif action == 2:  # Down\n",
    "            self.dot_position[1] = min(self.dot_position[1] + 1, 64 - 2)\n",
    "        elif action == 3:  # Left\n",
    "            self.dot_position[0] = max(self.dot_position[0] - 1, 0)\n",
    "\n",
    "        # Compute the reward based on the new position of the dot\n",
    "        reward = 0\n",
    "        for i, d in enumerate(self.colored_dots):\n",
    "            if sum(np.abs(self.dot_position - d[0])) <= 1:\n",
    "                # we hit the dot!\n",
    "                reward += 1\n",
    "                self.colored_dots.pop(i)\n",
    "                break\n",
    "            \n",
    "        self.current_step += 1\n",
    "        done = len(self.colored_dots) == 0 or self.current_step >= 1000\n",
    "        info = {}\n",
    "\n",
    "        # Update the observation\n",
    "        observation = self.get_obs()\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def render_dot(self, obs, position, color):\n",
    "        obs[position[1]:position[1]+2, position[0]:position[0]+2] = color\n",
    "    \n",
    "    def get_obs(self):\n",
    "        observation = np.zeros((64, 64, 3), dtype=np.uint8)\n",
    "\n",
    "        # render the dots in reverse order to ensure that the target is always visible\n",
    "        for p, c in reversed(self.colored_dots):\n",
    "            self.render_dot(observation, p, c)\n",
    "\n",
    "        self.render_dot(observation, self.dot_position, np.array([255, 255, 255]))\n",
    "        return observation\n",
    "    \n",
    "    def rand_point(self):\n",
    "        return np.array([np.random.randint(0, 64 - 2), np.random.randint(0, 64 - 2)])\n",
    "        \n",
    "    def reset(self):\n",
    "        self.dot_position = self.rand_point()\n",
    "        self.current_step = 0\n",
    "        self.colored_dots = []\n",
    "        for i in range(64):\n",
    "            self.colored_dots.append((self.rand_point(), np.array([0, 255, 0])))\n",
    "        observation = self.get_obs()\n",
    "        return observation\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.SimpleImageViewer()\n",
    "        self.viewer.imshow(self.get_obs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74c07384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 10\n"
     ]
    }
   ],
   "source": [
    "env = CollectDotsEnv()\n",
    "observation = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    action = env.action_space.sample()  # Replace with your policy\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "#     env.render()\n",
    "print(f'Total reward: {total_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fbb38e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 8.3      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10       |\n",
      "|    fps              | 2905     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 10000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 7.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 20000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 7.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 30       |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 30000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 7.47     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 2889     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 40000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 7.56     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 50       |\n",
      "|    fps              | 2889     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 50000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 7.32     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 1888     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 6.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 70       |\n",
      "|    fps              | 1507     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.65e-05 |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 6.34     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 1312     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000114 |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 5.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 90       |\n",
      "|    fps              | 1192     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.9e-05  |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 5.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1110     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28e-05 |\n",
      "|    n_updates        | 12499    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7fa924500040>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CollectDotsEnv()\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1, gamma=0.0)\n",
    "model.learn(total_timesteps=100000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8499cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 9.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 2054     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 7.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1022        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016474059 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00819    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 0.0351      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 7.29       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 870        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01580206 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.544      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0265    |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    value_loss           | 0.0201     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 6.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 810         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021508962 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0605     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.0233      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 6.08      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 779       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0204009 |\n",
      "|    clip_fraction        | 0.261     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.32     |\n",
      "|    explained_variance   | 0.494     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0427   |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0225   |\n",
      "|    value_loss           | 0.0218    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 758         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022170674 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0342     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 0.017       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 744         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022085726 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0235     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.0225      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 736         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028265294 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 0.0283      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026409853 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000419   |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 0.0253      |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Parallel environments\n",
    "env = make_vec_env(CollectDotsEnv, n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "409db567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1212     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.902   |\n",
      "|    explained_variance | 0.931    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0011  |\n",
      "|    value_loss         | 1.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.5      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1216     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.0036  |\n",
      "|    value_loss         | 6.87e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.5      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1221     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.31    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.00994 |\n",
      "|    value_loss         | 0.000492 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.75     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1224     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.00551 |\n",
      "|    value_loss         | 0.000106 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.75     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1252     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.0125  |\n",
      "|    value_loss         | 0.000252 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1271     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.704    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.00247  |\n",
      "|    value_loss         | 9.68e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1277     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.00116 |\n",
      "|    value_loss         | 1.94e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 1275     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0218  |\n",
      "|    value_loss         | 0.000322 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 1289     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0.98     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.00475 |\n",
      "|    value_loss         | 0.000205 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | 4.5       |\n",
      "| time/                 |           |\n",
      "|    fps                | 1300      |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.31     |\n",
      "|    explained_variance | 0.973     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -6.15e-05 |\n",
      "|    value_loss         | 5.52e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.5      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1310     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.00117 |\n",
      "|    value_loss         | 3.74e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1319     |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.00553  |\n",
      "|    value_loss         | 5.53e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1326     |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.209    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.199    |\n",
      "|    value_loss         | 0.0938   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.57     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1333     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.996    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.00508 |\n",
      "|    value_loss         | 2.38e-05 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.57     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1339     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.0133  |\n",
      "|    value_loss         | 0.000244 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | 5         |\n",
      "| time/                 |           |\n",
      "|    fps                | 1345      |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.27     |\n",
      "|    explained_variance | 0.999     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -0.000978 |\n",
      "|    value_loss         | 9.59e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 1349     |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.00191 |\n",
      "|    value_loss         | 7.36e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1352     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.989    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.0021  |\n",
      "|    value_loss         | 9.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1346     |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.00621 |\n",
      "|    value_loss         | 0.000112 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.95     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1343     |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0.902    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.00445 |\n",
      "|    value_loss         | 8.11e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | 4.95      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1345      |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.904    |\n",
      "|    explained_variance | 0.971     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -0.000636 |\n",
      "|    value_loss         | 3.35e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | 4.89      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1344      |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.975    |\n",
      "|    explained_variance | 0.996     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -0.000938 |\n",
      "|    value_loss         | 2.74e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 4.89     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1348     |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.0101  |\n",
      "|    value_loss         | 0.000167 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.04     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1350     |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.994    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.00176  |\n",
      "|    value_loss         | 6.89e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.04     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1353     |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.0114  |\n",
      "|    value_loss         | 0.000713 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.08     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1356     |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.00185  |\n",
      "|    value_loss         | 1.75e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.08     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1358     |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | 0.718    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.00944  |\n",
      "|    value_loss         | 0.000125 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.18     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1361     |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 0.995    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.00575  |\n",
      "|    value_loss         | 7.15e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.18     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1363     |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.00305 |\n",
      "|    value_loss         | 6.18e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.17     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1364     |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.0128  |\n",
      "|    value_loss         | 0.000171 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.17     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1366     |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.00134 |\n",
      "|    value_loss         | 2.63e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.25     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1368     |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 0.523    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.0638   |\n",
      "|    value_loss         | 0.0954   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | 5.25      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1369      |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.08     |\n",
      "|    explained_variance | 0.962     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -0.000589 |\n",
      "|    value_loss         | 4.13e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | 5.12      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1367      |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.18     |\n",
      "|    explained_variance | 0.997     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -0.000769 |\n",
      "|    value_loss         | 6.59e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.12     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1368     |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0.994    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.017   |\n",
      "|    value_loss         | 0.00306  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.14     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1370     |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.0219  |\n",
      "|    value_loss         | 0.000527 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.14     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1370     |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.253    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.162    |\n",
      "|    value_loss         | 0.0967   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.21     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1366     |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.00827 |\n",
      "|    value_loss         | 0.000205 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.21     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1363     |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.993    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.000541 |\n",
      "|    value_loss         | 9.78e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.3      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1360     |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.00013  |\n",
      "|    value_loss         | 3.6e-07  |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.3      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1357     |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.836   |\n",
      "|    explained_variance | 0.981    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.00347 |\n",
      "|    value_loss         | 2.15e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.36     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1357     |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.994    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.00451 |\n",
      "|    value_loss         | 0.000105 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.36     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1354     |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.00719 |\n",
      "|    value_loss         | 6.77e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.48     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1353     |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.789    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.031    |\n",
      "|    value_loss         | 0.0469   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.48     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1353     |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.801   |\n",
      "|    explained_variance | 0.999    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.000732 |\n",
      "|    value_loss         | 6.53e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | 5.5       |\n",
      "| time/                 |           |\n",
      "|    fps                | 1355      |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.909    |\n",
      "|    explained_variance | 0.999     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -2.52e-05 |\n",
      "|    value_loss         | 2.24e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.5      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1356     |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.994   |\n",
      "|    explained_variance | 0.964    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.00455 |\n",
      "|    value_loss         | 8.9e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1355     |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.00716 |\n",
      "|    value_loss         | 8.89e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1353     |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.393    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.137    |\n",
      "|    value_loss         | 0.189    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 5.5      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1351     |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.996    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.00228  |\n",
      "|    value_loss         | 1.73e-05 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7fa8480f88b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Parallel environments\n",
    "env = make_vec_env(CollectDotsEnv, n_envs=4)\n",
    "\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62a7a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "action_to_vector = {\n",
    "    0: np.array([0, -1]),  # Up\n",
    "    1: np.array([1, 0]),   # Right\n",
    "    2: np.array([0, 1]),   # Down\n",
    "    3: np.array([-1, 0])   # Left\n",
    "}\n",
    "\n",
    "class SparseDotEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.width = 64\n",
    "        self.height = 64\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(self.height, self.width, 3), dtype=np.uint8)\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.dot_position = np.array([0, 0], dtype='int32')\n",
    "        self.dot_color = np.array([255, 255, 255])\n",
    "        self.goal_position = np.array([self.width/2, self.height/2], dtype='int32')\n",
    "        self.viewer = None\n",
    "        self.reward_range = (-float('inf'), float('inf'))\n",
    "        self.max_episode_steps = 200\n",
    "        self.current_step = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        # Move the dot according to the action\n",
    "        if action == 0:  # Up\n",
    "            self.dot_position[1] = max(self.dot_position[1] - 1, 0)\n",
    "        elif action == 1:  # Right\n",
    "            self.dot_position[0] = min(self.dot_position[0] + 1, self.width - 2)\n",
    "        elif action == 2:  # Down\n",
    "            self.dot_position[1] = min(self.dot_position[1] + 1, self.height - 2)\n",
    "        elif action == 3:  # Left\n",
    "            self.dot_position[0] = max(self.dot_position[0] - 1, 0)\n",
    "\n",
    "        # Update the observation\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "\n",
    "        self.current_step += 1\n",
    "        finished = all(self.dot_position == self.goal_position)\n",
    "        done = self.current_step >= self.max_episode_steps or finished\n",
    "        info = {}\n",
    "        \n",
    "        reward = 1 if finished else 0\n",
    "\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def get_obs(self):\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "        return observation\n",
    "\n",
    "    def reset(self):\n",
    "        self.dot_position = np.array([np.random.randint(0, self.width - 2), np.random.randint(0, self.height - 2)])\n",
    "        observation = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        observation[self.dot_position[1]:self.dot_position[1]+2, self.dot_position[0]:self.dot_position[0]+2] = self.dot_color\n",
    "        self.current_step = 0\n",
    "        return observation\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.SimpleImageViewer()\n",
    "        self.viewer.imshow(self.reset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2784c995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marthinwurer/.pyenv/versions/3.9.6/envs/minerl/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 24.59GB > 23.08GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 200      |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10       |\n",
      "|    fps              | 9521     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 191      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 9538     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3819     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 194      |\n",
      "|    ep_rew_mean      | 0.0333   |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 30       |\n",
      "|    fps              | 9461     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5819     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 193      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 9424     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7725     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 194      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.0761   |\n",
      "| time/               |          |\n",
      "|    episodes         | 50       |\n",
      "|    fps              | 9402     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 9725     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 194      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 9418     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 11643    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 195      |\n",
      "|    ep_rew_mean      | 0.0429   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 70       |\n",
      "|    fps              | 9434     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13643    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.0375   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 9447     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15643    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.0333   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 90       |\n",
      "|    fps              | 9457     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17643    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 193      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 9464     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 19285    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 192      |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 110      |\n",
      "|    fps              | 9467     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 21185    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 194      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 9473     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 23185    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 194      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 130      |\n",
      "|    fps              | 9479     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25185    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 195      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 9483     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27185    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 194      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 150      |\n",
      "|    fps              | 9475     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 29105    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 195      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 9466     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 31105    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 193      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 170      |\n",
      "|    fps              | 9472     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 32962    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 193      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 9477     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 34962    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 193      |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 190      |\n",
      "|    fps              | 9482     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36945    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 197      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 9472     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 38945    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 210      |\n",
      "|    fps              | 9476     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 40945    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 9479     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 42765    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 230      |\n",
      "|    fps              | 9479     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 44747    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 9483     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 46747    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 250      |\n",
      "|    fps              | 9486     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 48747    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 8233     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 50747    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.56e-05 |\n",
      "|    n_updates        | 186      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 270      |\n",
      "|    fps              | 6204     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 52747    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.02e-06 |\n",
      "|    n_updates        | 686      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 5063     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 54747    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.35e-06 |\n",
      "|    n_updates        | 1186     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 290      |\n",
      "|    fps              | 4288     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 56747    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.79e-06 |\n",
      "|    n_updates        | 1686     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 3796     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 58548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11e-06 |\n",
      "|    n_updates        | 2136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 310      |\n",
      "|    fps              | 3415     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 60548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.6e-06  |\n",
      "|    n_updates        | 2636     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 62548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.18e-06 |\n",
      "|    n_updates        | 3136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 330      |\n",
      "|    fps              | 2889     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 64548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.14e-06 |\n",
      "|    n_updates        | 3636     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 2700     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 66548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e-06 |\n",
      "|    n_updates        | 4136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 350      |\n",
      "|    fps              | 2542     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 68548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58e-06 |\n",
      "|    n_updates        | 4636     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 2409     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 70548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.37e-07 |\n",
      "|    n_updates        | 5136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 370      |\n",
      "|    fps              | 2295     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 72548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.29e-06 |\n",
      "|    n_updates        | 5636     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 2192     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 74548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.25e-06 |\n",
      "|    n_updates        | 6136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 390      |\n",
      "|    fps              | 2101     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 76548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58e-06 |\n",
      "|    n_updates        | 6636     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 200      |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 2021     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 78548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e-06 |\n",
      "|    n_updates        | 7136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 200      |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 410      |\n",
      "|    fps              | 1951     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 80548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.22e-07 |\n",
      "|    n_updates        | 7636     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 1889     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 82491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04e-06 |\n",
      "|    n_updates        | 8122     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 430      |\n",
      "|    fps              | 1833     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 84491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59e-06 |\n",
      "|    n_updates        | 8622     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 1782     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 86491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.25e-06 |\n",
      "|    n_updates        | 9122     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 450      |\n",
      "|    fps              | 1737     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 88491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1e-06  |\n",
      "|    n_updates        | 9622     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 1695     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 90491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.1e-07  |\n",
      "|    n_updates        | 10122    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 470      |\n",
      "|    fps              | 1656     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 92491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1e-06  |\n",
      "|    n_updates        | 10622    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 1621     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 94491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.4e-07  |\n",
      "|    n_updates        | 11122    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 490      |\n",
      "|    fps              | 1591     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 96377    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.75e-07 |\n",
      "|    n_updates        | 11594    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 1562     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 98377    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.08e-07 |\n",
      "|    n_updates        | 12094    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7fa8480f8d90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = SparseDotEnv()\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1, gamma=0.0)\n",
    "model.learn(total_timesteps=100000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59560e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
